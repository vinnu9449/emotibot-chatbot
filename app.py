
import streamlit as st
from transformers import pipeline
from gtts import gTTS
import os

st.title("ğŸ­ EmotiBot - Emotion-Based Chat Companion")
st.write("Talk to me! Iâ€™ll detect your emotion and reply with empathy.")

emotion_model = pipeline("text-classification", model="bhadresh-savani/distilbert-base-uncased-emotion", top_k=1)

if 'chat_history' not in st.session_state:
    st.session_state.chat_history = []

user_input = st.text_input("You:")

def generate_response(user_input):
    prediction = emotion_model(user_input)[0][0]  # Access inner dict
    label = prediction['label']
    responses = {
        "joy": "Yay! Thatâ€™s great to hear ğŸ˜Š",
        "sadness": "Iâ€™m here for you. Wanna talk? ğŸ’™",
        "anger": "Take a deep breath. Youâ€™ve got this ğŸ’ª",
        "fear": "Donâ€™t worry, youâ€™re not alone ğŸ«‚",
        "love": "Aww, thatâ€™s sweet! â¤ï¸",
        "surprise": "Whoa! Thatâ€™s unexpected! ğŸ˜²",
        "neutral": "Tell me more! Iâ€™m all ears ğŸ‘‚"
    }
    return responses.get(label, "Iâ€™m not sure how to respond... but Iâ€™m listening!")

if user_input:
    response = generate_response(user_input)
    st.session_state.chat_history.append(("You", user_input))
    st.session_state.chat_history.append(("Bot", response))
    st.markdown(f"**Bot:** {response}")

st.markdown("### Chat History:")
for speaker, msg in st.session_state.chat_history:
    st.write(f"**{speaker}:** {msg}")
